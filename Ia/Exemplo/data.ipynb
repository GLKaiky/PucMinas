{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0c36ed-7c45-414f-8d7c-18061672b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.72.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8569d72c-9b42-4869-943c-0a8741957dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de texto carregados.\n"
     ]
    }
   ],
   "source": [
    "# Célula 1: Configuração e Definição dos Dados\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Frases de exemplo com dependência de longo prazo\n",
    "# Estas frases são projetadas para que a última palavra dependa de uma palavra anterior na sequência.\n",
    "text_data = [\n",
    "    \"O gato que estava no telhado, pulou para a árvore e depois de um tempo, miou.\",\n",
    "    \"O cachorro que correu pelo parque, brincou com a bola e finalmente, latia.\",\n",
    "    \"A criança que jogava no jardim, encontrou um brinquedo e começou a chorar.\",\n",
    "    \"O gato que comeu a ração, bebeu água e depois de um cochilo, miou.\",\n",
    "    \"O cachorro que farejou o chão, encontrou um osso e em seguida, latia.\",\n",
    "    \"A criança que desenhava na parede, foi repreendida e por fim, chorar.\",\n",
    "    \"O pássaro que voava alto, pousou no galho e então, cantou.\",\n",
    "    \"O leão que rugia na savana, caçou sua presa e depois, dormiu.\"\n",
    "]\n",
    "\n",
    "print(\"Dados de texto carregados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f04167e-d3fc-4abe-8b85-69ec00d89298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 65\n",
      "Mapeamento de palavras (amostra): [('<unk>', 1), ('que', 2), ('e', 3), ('o', 4), ('a', 5), ('um', 6), ('no', 7), ('depois', 8), ('gato', 9), ('de', 10)]...\n",
      "\n",
      "Comprimento máximo da sequência: 16\n",
      "Formato de X (entrada): (96, 15)\n",
      "Formato de y (saída one-hot): (96, 65)\n",
      "\n",
      "Exemplo de X (entrada para a LSTM):\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]\n",
      "Exemplo de y (saída one-hot esperada):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Célula 2: Pré-processamento dos Dados\n",
    "\n",
    "# 1. Tokenização e Criação do Vocabulário\n",
    "# O Tokenizer converte palavras em IDs numéricos e constrói o vocabulário.\n",
    "# <unk> é um token para palavras \"out-of-vocabulary\" (fora do vocabulário).\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(text_data) # Constrói o vocabulário a partir dos dados de texto\n",
    "word_index = tokenizer.word_index # Mapeamento palavra -> ID\n",
    "vocab_size = len(word_index) + 1 # +1 para o token <unk>\n",
    "\n",
    "print(f\"Tamanho do vocabulário: {vocab_size}\")\n",
    "print(f\"Mapeamento de palavras (amostra): {list(word_index.items())[:10]}...\") # Mostra as 10 primeiras\n",
    "\n",
    "# 2. Criar Sequências de Treinamento\n",
    "# Para cada frase, geramos múltiplas sequências de entrada/saída.\n",
    "# Ex: \"O gato miou.\" -> (\"O\", \"gato\"), (\"O gato\", \"miou\")\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    # Converte a frase em uma sequência de IDs numéricos\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        # Cria n-gramas (sequências crescentes)\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# 3. Padding das Sequências\n",
    "# Garante que todas as sequências de entrada tenham o mesmo comprimento,\n",
    "# o que é necessário para a entrada da rede neural.\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "padded_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# 4. Separar Entrada (X) e Saída (y)\n",
    "# X: todas as palavras da sequência, exceto a última (que é a entrada para a LSTM)\n",
    "# y: a última palavra da sequência (que é a saída esperada)\n",
    "X = padded_sequences[:, :-1]\n",
    "y = padded_sequences[:, -1]\n",
    "\n",
    "# 5. One-Hot Encode da Saída\n",
    "# Converte os IDs numéricos da saída em vetores one-hot,\n",
    "# onde cada posição representa uma palavra no vocabulário.\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(f\"\\nComprimento máximo da sequência: {max_sequence_len}\")\n",
    "print(f\"Formato de X (entrada): {X.shape}\")\n",
    "print(f\"Formato de y (saída one-hot): {y.shape}\")\n",
    "print(f\"\\nExemplo de X (entrada para a LSTM):\\n{X[0]}\")\n",
    "print(f\"Exemplo de y (saída one-hot esperada):\\n{y[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272f8947-4513-43a3-ad56-59cea9819643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glkaiky/Desktop/PucMinas/Ia/Exemplo/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-06-04 08:07:53.735984: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Célula 3: Construção e Compilação do Modelo LSTM\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Dimensões do Embedding\n",
    "# O embedding_dim define o tamanho do vetor denso que representará cada palavra.\n",
    "embedding_dim = 100\n",
    "\n",
    "# Construção do Modelo Sequencial\n",
    "model = Sequential([\n",
    "    # Camada de Embedding: Converte IDs de palavras em vetores densos.\n",
    "    # vocab_size: número total de palavras únicas.\n",
    "    # embedding_dim: dimensão dos vetores de palavras.\n",
    "    # input_length: comprimento das sequências de entrada (max_sequence_len - 1, pois a última é a saída).\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_sequence_len-1),\n",
    "\n",
    "    # Camada LSTM: A camada principal que processa a sequência e mantém a \"memória\".\n",
    "    # 150: número de unidades/neurônios na camada LSTM.\n",
    "    # return_sequences=False: A camada LSTM retorna apenas a saída do último passo da sequência,\n",
    "    #                         adequado para tarefas de classificação de sequência para um único rótulo.\n",
    "    LSTM(150, return_sequences=False),\n",
    "\n",
    "    # Camada Densa de Saída: Classifica a próxima palavra.\n",
    "    # vocab_size: número de classes (uma para cada palavra no vocabulário).\n",
    "    # activation='softmax': Garante que a saída seja uma distribuição de probabilidade sobre o vocabulário.\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilação do Modelo\n",
    "# loss='categorical_crossentropy': Função de perda para classificação multiclasse one-hot encoded.\n",
    "# optimizer='adam': Otimizador Adam, uma boa escolha padrão para a maioria dos modelos de DL.\n",
    "# metrics=['accuracy']: Métrica para monitorar o desempenho durante o treinamento.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Exibe um resumo da arquitetura do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b863654-e947-4d67-858c-67a7099b920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento do modelo...\n",
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0599 - loss: 4.1718\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1354 - loss: 4.1479\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0977 - loss: 4.1085\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0964 - loss: 4.0189\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0964 - loss: 3.9051\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1250 - loss: 3.8016\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1341 - loss: 3.8813\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1380 - loss: 3.8639\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1562 - loss: 3.7332\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1484 - loss: 3.7141\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1576 - loss: 3.6694\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1771 - loss: 3.5254\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1693 - loss: 3.4458\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1862 - loss: 3.3973\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1706 - loss: 3.4042\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1823 - loss: 3.2128\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1549 - loss: 3.2216\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1758 - loss: 3.1812\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1628 - loss: 3.1423\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1654 - loss: 3.0557\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2344 - loss: 2.9274\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2656 - loss: 2.8638\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2604 - loss: 2.7794\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2031 - loss: 2.8174\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2747 - loss: 2.6327\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2682 - loss: 2.6638\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3125 - loss: 2.5431\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3438 - loss: 2.4468\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3229 - loss: 2.4654\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3216 - loss: 2.3516\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3581 - loss: 2.3276\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3633 - loss: 2.2711\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3698 - loss: 2.2419\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3516 - loss: 2.1610\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3763 - loss: 2.1098\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4596 - loss: 1.9880\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4245 - loss: 1.9239\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5039 - loss: 1.9079\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5417 - loss: 1.8447\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5586 - loss: 1.7335\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5417 - loss: 1.7329\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6055 - loss: 1.5548\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6732 - loss: 1.5764\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6940 - loss: 1.4133\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7109 - loss: 1.4953\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6979 - loss: 1.4135\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7708 - loss: 1.3121\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7435 - loss: 1.2907\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8372 - loss: 1.1861\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 1.1641\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7969 - loss: 1.1192\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8359 - loss: 1.1246\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8490 - loss: 1.0110\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8685 - loss: 0.9947\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8958 - loss: 0.9527\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8411 - loss: 0.9421\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8672 - loss: 0.8871\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8659 - loss: 0.8321\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8672 - loss: 0.8263\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8451 - loss: 0.8608\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8893 - loss: 0.7958\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8763 - loss: 0.7232\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9023 - loss: 0.6704\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8815 - loss: 0.6864\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8958 - loss: 0.6346\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9010 - loss: 0.6561\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8815 - loss: 0.6304\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9115 - loss: 0.5547\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9076 - loss: 0.6033\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9362 - loss: 0.5265\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9154 - loss: 0.5452\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9010 - loss: 0.5127\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9180 - loss: 0.4913\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9310 - loss: 0.4729\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9154 - loss: 0.5270\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9349 - loss: 0.4564\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9245 - loss: 0.4895\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9440 - loss: 0.4302\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9271 - loss: 0.4418\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9284 - loss: 0.4450\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9323 - loss: 0.4454\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9154 - loss: 0.4199\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9518 - loss: 0.3568\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9115 - loss: 0.4042\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9479 - loss: 0.3625\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9102 - loss: 0.3925\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9076 - loss: 0.3770\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9154 - loss: 0.3834\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8919 - loss: 0.3430\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9349 - loss: 0.3338\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9193 - loss: 0.3347\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9089 - loss: 0.3235\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9193 - loss: 0.3256\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9362 - loss: 0.3349\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9193 - loss: 0.3235\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8984 - loss: 0.3328\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9167 - loss: 0.3265\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9362 - loss: 0.2861\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9154 - loss: 0.2633\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9362 - loss: 0.2820\n",
      "\n",
      "Treinamento concluído.\n"
     ]
    }
   ],
   "source": [
    "# Célula 4: Treinamento do Modelo\n",
    "\n",
    "print(\"Iniciando o treinamento do modelo...\")\n",
    "\n",
    "# model.fit: Treina o modelo com os dados de entrada (X) e saída (y).\n",
    "# epochs: Número de vezes que o modelo verá todo o dataset. 100 épocas são suficientes para este dataset pequeno.\n",
    "# verbose=1: Exibe o progresso do treinamento em cada época.\n",
    "history = model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "print(\"\\nTreinamento concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454c2bd1-69e9-4007-b6b3-321989d9faae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função 'predict_next_word' definida.\n"
     ]
    }
   ],
   "source": [
    "# Célula 5: Função para Prever a Próxima Palavra\n",
    "\n",
    "def predict_next_word(model, tokenizer, text_sequence, max_len):\n",
    "    \"\"\"\n",
    "    Prevê a próxima palavra em uma sequência de texto.\n",
    "\n",
    "    Args:\n",
    "        model: O modelo LSTM treinado.\n",
    "        tokenizer: O Tokenizer usado para pré-processar os dados de treinamento.\n",
    "        text_sequence: A sequência de texto de entrada (string).\n",
    "        max_len: O comprimento máximo das sequências de entrada (max_sequence_len do pré-processamento).\n",
    "\n",
    "    Returns:\n",
    "        A palavra prevista como string.\n",
    "    \"\"\"\n",
    "    # Converte a sequência de texto em IDs numéricos\n",
    "    token_list = tokenizer.texts_to_sequences([text_sequence])[0]\n",
    "    \n",
    "    # Faz o padding da sequência para corresponder ao comprimento de entrada do modelo\n",
    "    # max_len-1 porque a camada de Embedding espera o comprimento da sequência de entrada (X),\n",
    "    # que é o comprimento máximo - 1 (a última palavra é a saída).\n",
    "    padded_token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
    "    \n",
    "    # Obtém as probabilidades de cada palavra no vocabulário ser a próxima\n",
    "    predicted_probabilities = model.predict(padded_token_list, verbose=0)[0]\n",
    "    \n",
    "    # Encontra o índice da palavra com a maior probabilidade\n",
    "    predicted_word_index = np.argmax(predicted_probabilities)\n",
    "    \n",
    "    # Mapeia o índice de volta para a palavra correspondente\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    \n",
    "    # Retorna <unk> se a palavra prevista não for encontrada (improvável com nosso vocabulário)\n",
    "    return \"<unk>\"\n",
    "\n",
    "print(\"Função 'predict_next_word' definida.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb958a8-7fc3-4e44-a183-bbb96a64a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Previsões de Frases Completas ---\n",
      "Início: 'O gato que estava no telhado' -> Frase completa prevista: 'O gato que estava no telhado pulou para a árvore e depois de um tempo miou'\n",
      "Início: 'O cachorro que correu pelo parque, brincou com a bola e finalmente' -> Frase completa prevista: 'O cachorro que correu pelo parque, brincou com a bola e finalmente latia miou miou miou miou miou miou miou miou miou'\n",
      "Início: 'A criança que jogava no jardim, encontrou um brinquedo e começou a' -> Frase completa prevista: 'A criança que jogava no jardim, encontrou um brinquedo e começou a chorar chorar miou miou miou miou miou miou miou miou'\n",
      "Início: 'O gato que comeu a ração, bebeu água e depois de um cochilo' -> Frase completa prevista: 'O gato que comeu a ração, bebeu água e depois de um cochilo miou miou miou miou miou miou miou miou miou miou'\n",
      "Início: 'O cachorro que farejou o chão, encontrou um osso e em seguida' -> Frase completa prevista: 'O cachorro que farejou o chão, encontrou um osso e em seguida latia latia miou miou miou miou miou miou miou que'\n",
      "Início: 'A criança que desenhava na parede, foi repreendida e por fim' -> Frase completa prevista: 'A criança que desenhava na parede, foi repreendida e por fim chorar chorar miou miou miou miou miou que ração bebeu'\n",
      "Início: 'O pássaro que voava alto, pousou no galho e então' -> Frase completa prevista: 'O pássaro que voava alto, pousou no galho e então cantou um chorar miou miou miou miou miou chorar miou'\n",
      "Início: 'O leão que rugia na savana, caçou sua presa e depois' -> Frase completa prevista: 'O leão que rugia na savana, caçou sua presa e depois dormiu latia miou miou miou miou miou miou miou miou'\n",
      "\n",
      "Início Longo (dependência distante): 'O gato, que estava dormindo profundamente em sua cama macia, e que sonhava com peixes, agora acordou e vai' -> Frase completa prevista: 'O gato, que estava dormindo profundamente em sua cama macia, e que sonhava com peixes, agora acordou e vai miou miou miou miou miou miou miou miou miou que'\n",
      "Início Longo (dependência distante): 'O cachorro, que fugiu da coleira, e correu por toda a rua, agora parou e vai' -> Frase completa prevista: 'O cachorro, que fugiu da coleira, e correu por toda a rua, agora parou e vai miou miou miou miou miou miou miou miou miou que'\n",
      "\n",
      "--- Fim da Demonstração ---\n"
     ]
    }
   ],
   "source": [
    "# Célula 6: Teste e Demonstração das Previsões\n",
    "\n",
    "# Função para prever a frase completa\n",
    "def predict_full_phrase(model, tokenizer, start_text_sequence, max_input_len, max_output_words=10):\n",
    "    \"\"\"\n",
    "    Prevê a frase completa a partir de uma sequência inicial, palavra por palavra.\n",
    "\n",
    "    Args:\n",
    "        model: O modelo LSTM treinado.\n",
    "        tokenizer: O Tokenizer usado para pré-processar os dados de treinamento.\n",
    "        start_text_sequence: A sequência de texto inicial (string).\n",
    "        max_input_len: O comprimento máximo das sequências de entrada para o modelo (max_sequence_len do pré-processamento).\n",
    "        max_output_words: O número máximo de palavras a serem geradas após a sequência inicial.\n",
    "\n",
    "    Returns:\n",
    "        A frase completa gerada.\n",
    "    \"\"\"\n",
    "    generated_phrase = start_text_sequence\n",
    "    for _ in range(max_output_words):\n",
    "        token_list = tokenizer.texts_to_sequences([generated_phrase])[0]\n",
    "        # Pad a sequência para o comprimento de entrada do modelo\n",
    "        # max_len-1 porque a camada de Embedding espera o comprimento da sequência de entrada (X),\n",
    "        # que é o comprimento máximo - 1 (a última palavra é a saída).\n",
    "        padded_token_list = pad_sequences([token_list], maxlen=max_input_len - 1, padding='pre')\n",
    "\n",
    "        # Preveja a próxima palavra\n",
    "        predicted_probabilities = model.predict(padded_token_list, verbose=0)[0]\n",
    "        predicted_word_index = np.argmax(predicted_probabilities)\n",
    "\n",
    "        predicted_word = \"\"\n",
    "        # Mapear índice de volta para palavra\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_word_index:\n",
    "                predicted_word = word\n",
    "                break\n",
    "        \n",
    "        # Se a palavra prevista for um token de fim de frase ou um token desconhecido, pare.\n",
    "        # Ajuste esta condição conforme os tokens que você espera para o fim da frase.\n",
    "        if predicted_word == \".\" or predicted_word == \"<unk>\" or predicted_word == \"\":\n",
    "            break\n",
    "        \n",
    "        generated_phrase += \" \" + predicted_word\n",
    "    return generated_phrase\n",
    "\n",
    "# Frases para testar o modelo (apenas o início)\n",
    "test_phrases = [\n",
    "    \"O gato que estava no telhado\",\n",
    "    \"O cachorro que correu pelo parque, brincou com a bola e finalmente\",\n",
    "    \"A criança que jogava no jardim, encontrou um brinquedo e começou a\",\n",
    "    \"O gato que comeu a ração, bebeu água e depois de um cochilo\",\n",
    "    \"O cachorro que farejou o chão, encontrou um osso e em seguida\",\n",
    "    \"A criança que desenhava na parede, foi repreendida e por fim\",\n",
    "    \"O pássaro que voava alto, pousou no galho e então\",\n",
    "    \"O leão que rugia na savana, caçou sua presa e depois\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Previsões de Frases Completas ---\")\n",
    "for phrase in test_phrases:\n",
    "    full_predicted_phrase = predict_full_phrase(model, tokenizer, phrase, max_sequence_len)\n",
    "    print(f\"Início: '{phrase}' -> Frase completa prevista: '{full_predicted_phrase}'\")\n",
    "\n",
    "# Exemplo de uma frase com uma dependência longa e uma palavra-chave no meio\n",
    "# Esta frase é mais longa e com \"distratores\" para mostrar a capacidade da LSTM\n",
    "# de manter a memória do sujeito (\"gato\") ao longo da sequência.\n",
    "new_long_phrase = \"O gato, que estava dormindo profundamente em sua cama macia, e que sonhava com peixes, agora acordou e vai\"\n",
    "full_predicted_phrase_long = predict_full_phrase(model, tokenizer, new_long_phrase, max_sequence_len)\n",
    "print(f\"\\nInício Longo (dependência distante): '{new_long_phrase}' -> Frase completa prevista: '{full_predicted_phrase_long}'\")\n",
    "\n",
    "# Exemplo de outra frase longa\n",
    "new_long_phrase_2 = \"O cachorro, que fugiu da coleira, e correu por toda a rua, agora parou e vai\"\n",
    "full_predicted_phrase_long_2 = predict_full_phrase(model, tokenizer, new_long_phrase_2, max_sequence_len)\n",
    "print(f\"Início Longo (dependência distante): '{new_long_phrase_2}' -> Frase completa prevista: '{full_predicted_phrase_long_2}'\")\n",
    "\n",
    "print(\"\\n--- Fim da Demonstração ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2943f9a-fff4-4901-97ae-4f3d0953b170",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
