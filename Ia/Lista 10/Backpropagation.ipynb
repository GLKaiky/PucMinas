{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d148646-d7bd-4a61-bf27-be88f9df2500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.10.3)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from tensorflow) (80.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.8/404.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419da6ab-8efa-4c35-9ca5-22319dd32395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, num_inputs, num_hidden_neurons, num_output_neurons, learning_rate, activation_function_name):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.num_output_neurons = num_output_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Inicializa pesos e biases aleatoriamente\n",
    "        self.weights_input_hidden = np.random.uniform(-1, 1, (self.num_inputs, self.num_hidden_neurons))\n",
    "        self.bias_hidden = np.random.uniform(-1, 1, (1, self.num_hidden_neurons))\n",
    "        self.weights_hidden_output = np.random.uniform(-1, 1, (self.num_hidden_neurons, self.num_output_neurons))\n",
    "        self.bias_output = np.random.uniform(-1, 1, (1, self.num_output_neurons))\n",
    "\n",
    "        # Define a função de ativação e sua derivada\n",
    "        self.activation_function, self.derivative_activation_function = self._get_activation_function(activation_function_name)\n",
    "\n",
    "    def _get_activation_function(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return self._sigmoid, self._sigmoid_derivative\n",
    "        elif name == 'tanh':\n",
    "            return self._tanh, self._tanh_derivative\n",
    "        elif name == 'relu':\n",
    "            return self._relu, self._relu_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Função de ativação não suportada. Escolha entre 'sigmoid', 'tanh', 'relu'.\")\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_derivative(self, x):\n",
    "        return x * (1 - x) # x aqui é a saída da função sigmoid\n",
    "\n",
    "    def _tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def _tanh_derivative(self, x):\n",
    "        return 1 - (x ** 2) # x aqui é a saída da função tanh\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _relu_derivative(self, x):\n",
    "        return (x > 0).astype(float) # x aqui é a saída da função relu\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        # Camada oculta\n",
    "        self.hidden_layer_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_layer_output = self.activation_function(self.hidden_layer_input)\n",
    "\n",
    "        # Camada de saída\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.predicted_output = self.activation_function(self.output_layer_input)\n",
    "        return self.predicted_output\n",
    "\n",
    "    def backpropagate(self, inputs, targets):\n",
    "        # Calcular o erro na camada de saída\n",
    "        error_output = targets - self.predicted_output\n",
    "\n",
    "        # Gradiente da camada de saída\n",
    "        # É importante usar a saída da função de ativação para calcular a derivada,\n",
    "        # e não a entrada líquida (net_o)\n",
    "        delta_output = error_output * self.derivative_activation_function(self.predicted_output)\n",
    "\n",
    "        # Calcular o erro na camada oculta\n",
    "        error_hidden = np.dot(delta_output, self.weights_hidden_output.T)\n",
    "\n",
    "        # Gradiente da camada oculta\n",
    "        delta_hidden = error_hidden * self.derivative_activation_function(self.hidden_layer_output)\n",
    "\n",
    "        # Atualizar pesos e biases da camada oculta para saída\n",
    "        self.weights_hidden_output += self.learning_rate * np.dot(self.hidden_layer_output.T, delta_output)\n",
    "        self.bias_output += self.learning_rate * np.sum(delta_output, axis=0, keepdims=True)\n",
    "\n",
    "        # Atualizar pesos e biases da camada de entrada para oculta\n",
    "        self.weights_input_hidden += self.learning_rate * np.dot(inputs.T, delta_hidden)\n",
    "        self.bias_hidden += self.learning_rate * np.sum(delta_hidden, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, training_data, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            total_error = 0\n",
    "            for inputs, targets in training_data:\n",
    "                inputs = np.array([inputs]) # Garante que as entradas sejam uma matriz 2D\n",
    "                targets = np.array([targets]) # Garante que os targets sejam uma matriz 2D\n",
    "\n",
    "                self.feedforward(inputs)\n",
    "                self.backpropagate(inputs, targets)\n",
    "\n",
    "                total_error += np.mean(np.abs(targets - self.predicted_output)) # MAE como métrica de erro\n",
    "            # print(f\"Época {epoch+1}/{epochs}, Erro: {total_error / len(training_data):.4f}\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = np.array([inputs]) # Garante que as entradas sejam uma matriz 2D\n",
    "        return self.feedforward(inputs)\n",
    "\n",
    "# --- Funções para gerar dados AND, OR, XOR ---\n",
    "def generate_boolean_data(num_inputs, gate_type):\n",
    "    data = []\n",
    "    # Itera sobre todas as combinações possíveis de entradas booleanas\n",
    "    for i in range(2**num_inputs):\n",
    "        binary_representation = bin(i)[2:].zfill(num_inputs)\n",
    "        inputs = [int(bit) for bit in binary_representation]\n",
    "        \n",
    "        target = 0\n",
    "        if gate_type == 'AND':\n",
    "            target = 1 if all(inputs) else 0\n",
    "        elif gate_type == 'OR':\n",
    "            target = 1 if any(inputs) else 0\n",
    "        elif gate_type == 'XOR':\n",
    "            target = sum(inputs) % 2 # XOR é 1 se o número de 1s for ímpar\n",
    "        else:\n",
    "            raise ValueError(\"Tipo de porta lógica inválido. Escolha 'AND', 'OR' ou 'XOR'.\")\n",
    "        \n",
    "        data.append((inputs, [target])) # O target também precisa ser uma lista para numpy\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50701de4-3187-4760-88dc-9320bba8ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Investigando a importância da Taxa de Aprendizado ---\n",
      "\n",
      "--- Experimentando: AND com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 4, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 0, Saída Prevista: 0.0237 (Classe: 0)\n",
      "Entrada: [1, 0], Saída Esperada: 0, Saída Prevista: 0.0228 (Classe: 0)\n",
      "Entrada: [1, 1], Saída Esperada: 1, Saída Prevista: 0.9625 (Classe: 1)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: AND com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.01, Neurônios Ocultos: 4, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0264 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 0, Saída Prevista: 0.2020 (Classe: 0)\n",
      "Entrada: [1, 0], Saída Esperada: 0, Saída Prevista: 0.2024 (Classe: 0)\n",
      "Entrada: [1, 1], Saída Esperada: 1, Saída Prevista: 0.7131 (Classe: 1)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: AND com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.5, Neurônios Ocultos: 4, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0004 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 0, Saída Prevista: 0.0093 (Classe: 0)\n",
      "Entrada: [1, 0], Saída Esperada: 0, Saída Prevista: 0.0095 (Classe: 0)\n",
      "Entrada: [1, 1], Saída Esperada: 1, Saída Prevista: 0.9862 (Classe: 1)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Investigando a importância da Função de Ativação ---\n",
      "\n",
      "--- Experimentando: XOR com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 4, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0444 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 1, Saída Prevista: 0.9599 (Classe: 1)\n",
      "Entrada: [1, 0], Saída Esperada: 1, Saída Prevista: 0.9518 (Classe: 1)\n",
      "Entrada: [1, 1], Saída Esperada: 0, Saída Prevista: 0.0391 (Classe: 0)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: XOR com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 4, Função de Ativação: tanh\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 1, Saída Prevista: 0.9908 (Classe: 1)\n",
      "Entrada: [1, 0], Saída Esperada: 1, Saída Prevista: 0.9911 (Classe: 1)\n",
      "Entrada: [1, 1], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: XOR com 2 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 4, Função de Ativação: relu\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0], Saída Esperada: 0, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [0, 1], Saída Esperada: 1, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [1, 0], Saída Esperada: 1, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [1, 1], Saída Esperada: 0, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Acurácia: 50.00%\n",
      "\n",
      "--- Testando com diferentes números de entradas ---\n",
      "\n",
      "--- Experimentando: AND com 3 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 8, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0, 0], Saída Esperada: 0, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [0, 0, 1], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Entrada: [0, 1, 0], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Entrada: [0, 1, 1], Saída Esperada: 0, Saída Prevista: 0.0224 (Classe: 0)\n",
      "Entrada: [1, 0, 0], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Entrada: [1, 0, 1], Saída Esperada: 0, Saída Prevista: 0.0224 (Classe: 0)\n",
      "Entrada: [1, 1, 0], Saída Esperada: 0, Saída Prevista: 0.0235 (Classe: 0)\n",
      "Entrada: [1, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9605 (Classe: 1)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: OR com 4 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 8, Função de Ativação: sigmoid\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0, 0, 0], Saída Esperada: 0, Saída Prevista: 0.0325 (Classe: 0)\n",
      "Entrada: [0, 0, 0, 1], Saída Esperada: 1, Saída Prevista: 0.9851 (Classe: 1)\n",
      "Entrada: [0, 0, 1, 0], Saída Esperada: 1, Saída Prevista: 0.9852 (Classe: 1)\n",
      "Entrada: [0, 0, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9996 (Classe: 1)\n",
      "Entrada: [0, 1, 0, 0], Saída Esperada: 1, Saída Prevista: 0.9845 (Classe: 1)\n",
      "Entrada: [0, 1, 0, 1], Saída Esperada: 1, Saída Prevista: 0.9995 (Classe: 1)\n",
      "Entrada: [0, 1, 1, 0], Saída Esperada: 1, Saída Prevista: 0.9995 (Classe: 1)\n",
      "Entrada: [0, 1, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9998 (Classe: 1)\n",
      "Entrada: [1, 0, 0, 0], Saída Esperada: 1, Saída Prevista: 0.9842 (Classe: 1)\n",
      "Entrada: [1, 0, 0, 1], Saída Esperada: 1, Saída Prevista: 0.9995 (Classe: 1)\n",
      "Entrada: [1, 0, 1, 0], Saída Esperada: 1, Saída Prevista: 0.9995 (Classe: 1)\n",
      "Entrada: [1, 0, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9998 (Classe: 1)\n",
      "Entrada: [1, 1, 0, 0], Saída Esperada: 1, Saída Prevista: 0.9994 (Classe: 1)\n",
      "Entrada: [1, 1, 0, 1], Saída Esperada: 1, Saída Prevista: 0.9998 (Classe: 1)\n",
      "Entrada: [1, 1, 1, 0], Saída Esperada: 1, Saída Prevista: 0.9998 (Classe: 1)\n",
      "Entrada: [1, 1, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9998 (Classe: 1)\n",
      "Acurácia: 100.00%\n",
      "\n",
      "--- Experimentando: XOR com 3 entradas ---\n",
      "Taxa de Aprendizado: 0.1, Neurônios Ocultos: 8, Função de Ativação: tanh\n",
      "\n",
      "Resultados do Teste:\n",
      "Entrada: [0, 0, 0], Saída Esperada: 0, Saída Prevista: 0.0001 (Classe: 0)\n",
      "Entrada: [0, 0, 1], Saída Esperada: 1, Saída Prevista: 0.9943 (Classe: 1)\n",
      "Entrada: [0, 1, 0], Saída Esperada: 1, Saída Prevista: 0.9935 (Classe: 1)\n",
      "Entrada: [0, 1, 1], Saída Esperada: 0, Saída Prevista: -0.0000 (Classe: 0)\n",
      "Entrada: [1, 0, 0], Saída Esperada: 1, Saída Prevista: 0.9946 (Classe: 1)\n",
      "Entrada: [1, 0, 1], Saída Esperada: 0, Saída Prevista: -0.0000 (Classe: 0)\n",
      "Entrada: [1, 1, 0], Saída Esperada: 0, Saída Prevista: 0.0000 (Classe: 0)\n",
      "Entrada: [1, 1, 1], Saída Esperada: 1, Saída Prevista: 0.9953 (Classe: 1)\n",
      "Acurácia: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Experimentos ---\n",
    "\n",
    "def run_experiment(gate_type, num_inputs, learning_rate, num_hidden_neurons, activation_function_name, epochs=10000):\n",
    "    print(f\"\\n--- Experimentando: {gate_type} com {num_inputs} entradas ---\")\n",
    "    print(f\"Taxa de Aprendizado: {learning_rate}, Neurônios Ocultos: {num_hidden_neurons}, Função de Ativação: {activation_function_name}\")\n",
    "\n",
    "    training_data = generate_boolean_data(num_inputs, gate_type)\n",
    "    nn = NeuralNetwork(num_inputs, num_hidden_neurons, 1, learning_rate, activation_function_name)\n",
    "    nn.train(training_data, epochs)\n",
    "\n",
    "    print(\"\\nResultados do Teste:\")\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for inputs, target in training_data:\n",
    "        prediction = nn.predict(inputs)[0][0]\n",
    "        # Para saídas booleanas, arredondamos para 0 ou 1\n",
    "        predicted_class = 1 if prediction >= 0.5 else 0 \n",
    "        \n",
    "        print(f\"Entrada: {inputs}, Saída Esperada: {target[0]}, Saída Prevista: {prediction:.4f} (Classe: {predicted_class})\")\n",
    "        if predicted_class == target[0]:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "    \n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Acurácia: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# 1) A importância da taxa de aprendizado\n",
    "print(\"\\n--- Investigando a importância da Taxa de Aprendizado ---\")\n",
    "# Para AND com 2 entradas, 4 neurônios ocultos, sigmoide\n",
    "run_experiment('AND', 2, 0.1, 4, 'sigmoid') # Taxa de aprendizado padrão\n",
    "run_experiment('AND', 2, 0.01, 4, 'sigmoid') # Taxa de aprendizado menor\n",
    "run_experiment('AND', 2, 0.5, 4, 'sigmoid')  # Taxa de aprendizado maior (pode oscilar)\n",
    "\n",
    "# 2) A importância do bias\n",
    "# O bias já está incluído na implementação da NeuralNetwork, \n",
    "# pois ele é crucial para redes neurais. \n",
    "# Para demonstrar sua importância, poderíamos criar uma versão sem bias, \n",
    "# mas isso geralmente leva a uma incapacidade de aprender.\n",
    "# A melhor forma de \"investigar\" é entender que sem ele, a rede não conseguiria \n",
    "# deslocar a função de ativação, o que é vital para separar dados não linearmente separáveis.\n",
    "\n",
    "# 3) A importância da função de ativação\n",
    "print(\"\\n--- Investigando a importância da Função de Ativação ---\")\n",
    "# Para XOR com 2 entradas, 4 neurônios ocultos (XOR é o melhor para ver a diferença)\n",
    "run_experiment('XOR', 2, 0.1, 4, 'sigmoid')\n",
    "run_experiment('XOR', 2, 0.1, 4, 'tanh')\n",
    "# RELU pode ter problemas de \"dying ReLU\" em alguns cenários e requer mais cuidado com a inicialização,\n",
    "# mas vamos testar para fins de demonstração.\n",
    "run_experiment('XOR', 2, 0.1, 4, 'relu') \n",
    "\n",
    "# Testes com diferentes números de entradas\n",
    "print(\"\\n--- Testando com diferentes números de entradas ---\")\n",
    "run_experiment('AND', 3, 0.1, 8, 'sigmoid') # AND com 3 entradas\n",
    "run_experiment('OR', 4, 0.1, 8, 'sigmoid')  # OR com 4 entradas\n",
    "run_experiment('XOR', 3, 0.1, 8, 'tanh')   # XOR com 3 entradas (mais complexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd863e17-ac9b-4d58-886d-701dcae99d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
